path:
  train_path: ./data/raw_data/total_data.csv # ./data/preprocessed_data/train.typed_entity_marker.csv
  test_path: ./data/raw_data/total_data.csv # ./data/preprocessed_data/train.typed_entity_marker.csv
  predict_path: ./data/raw_data/total_data.csv # ./data/preprocessed_data/test.typed_entity_marker.csv
  save_path: saved_models/
  resume_path: # checkpoint path for resuming training

data_preprocess:
  marker_type: None # entity_marker, entity_marker_punc, typed_entity_marker, typed_entity_makrer_punc_1~3

dataloader:
  shuffle: True
  train_ratio: 0.8
  architecture:  BaseDataloader # AuxiliaryDataloader

model:
  name: klue/bert-base
  architecture: BaseModel # AuxiliaryClassificationRobertaModel

tokenizer:
  new_tokens: []
  new_special_tokens: []
  max_length: 256
  syllable: False

train:
  max_epoch: 1
  batch_size: 128
  learning_rate: 1e-5
  loss: ce
  label_smoothing: 0.1
  use_frozen: False
  print_val_cm: True
  print_test_cm: True
  optimizer: AdamW
  scheduler: StepLR
  
utils:
  seed: 42
  monitor: val_f1
  patience: 25
  top_k: 3
  precision: 32 # 16(fp-16) is also possible
  on_step: True # whether to log val/test metrics step-wise. Train metrics will automatcially be logged step-wise. 

k_fold:
  use_k_fold: False
  num_folds: 3

ensemble:
  use_ensemble: False
  architecture: EnsembleVotingModel
  ckpt_paths: []

wandb:
  team_account_name: next-level-potato # 팀 계정
  project_repo: DA-jn  # 프로젝트 레포 이름
  name: jjn # 실험자 명
  info: dataset_annotation_test # 실험명