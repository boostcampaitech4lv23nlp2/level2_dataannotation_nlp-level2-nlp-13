path:
  train_path: ./data/raw_data/train.csv # ./data/raw_data/train.rm_duplicated.csv 
  test_path: ./data/raw_data/test.csv # ./data/raw_data/test.rm_duplicated.csv 
  predict_path: ./data/raw_data/predict.csv # ./data/raw_data/predict.rm_duplicated.csv 
  save_path: saved_models/
  resume_path: # checkpoint path for resuming training

data_preprocess:
  marker_type: None # entity_marker, entity_marker_punc, typed_entity_marker, typed_entity_makrer_punc_1~3

dataloader:
  shuffle: True
  train_ratio: 0.8
  architecture:  AuxiliaryDataloader # BaseDataloader 

model:
  name: klue/roberta-large
  architecture: AuxiliaryClassificationRobertaModel # BaseModel

tokenizer:
  new_tokens: []
  new_special_tokens: []
  max_length: 256
  syllable: False

train:
  max_epoch: 3
  batch_size: 8
  learning_rate: 1e-5
  loss: focal
  label_smoothing: 0.1
  use_frozen: False
  print_val_cm: True
  print_test_cm: True
  optimizer: AdamW
  scheduler: StepLR
  
utils:
  seed: 42
  monitor: val_f1
  patience: 25
  top_k: 3
  precision: 32 # 16(fp-16) is also possible
  on_step: True # whether to log val/test metrics step-wise. Train metrics will automatcially be logged step-wise. 

k_fold:
  use_k_fold: False
  num_folds: 3

ensemble:
  use_ensemble: False
  architecture: EnsembleVotingModel
  ckpt_paths: []

wandb:
  team_account_name: next-level-potato # 팀 계정
  project_repo: RE  # 프로젝트 레포 이름
  name: kbh # 실험자 명
  info: 2022-12-15-data_annotation # 실험명